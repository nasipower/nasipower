Teacher assessment and psychometric theory: a case of paradigm crossing? Alex Teasdale and Constant Leung King’s College, London Alternative assessment (as opposed to formal testing) is gaining a great deal of attention in current educational discussion. This article attempts to address some of the epistemic and practical issues facing alternative assessment, with particular reference to teacher assessment of spoken English as an additional language / second language (EAL/ESL) in the early years of primary (elementary) education in England and Wales. We first examine the claims made by advocates of alternative assessment in terms of validity and educational relevance. It is argued that such claims are founded on an uneasy articulation of different principles underpinning psychometric measurement and pedagogy. Next we look at some of the reasons why psychometric approaches may not provide an adequate response to pedagogic and policy developments. Then some of the theoretical and practical problems involved in teacher assessment of speaking, focusing on learners with EAL in primary education, are discussed. We focus on the importance of clarity about the epistemological bases of different types of assessment. Additionally, the article highlights the need to be alert to the ways in which political and ideological concerns – together with the influence of professional (teaching) culture – are influential in shaping the properties of assessment systems. I Introduction In the 1990s classroom-based language assessment became particularly common in multilingual mainstream classroom settings in Australia, Britain and North America and is used extensively with young learners at primary level. This phenomenon can in part be seen as a reflection of the trend in general education towards a broad range of alternative forms of assessment (Huerta-Marcı´as, 1995). It is also, in part, a reflection of the recognition by researchers, educators and policy makers of the flexibility of such an approach and the claims for validity made on its behalf. However, this increase in the frequency of use of classroom-based approaches to language assessment has its problems. This article seeks to examine some of the conceptual and practical difficulties encountered in the notion of teacher assessment with particular reference to its use within the National Curriculum in England and Wales. In particular, we discuss the problems of attempting to implement modes of assessment which are intended to satisfy the requirements of both learning and the measurement of achievement when insufficient attention has been given to the distinctive differences in the nature of knowledge which inform alternative and psychometric assessment. These problems are especially salient for pupils whose mother tongue is not English. In the discussion, we draw on our research into the assessment of speaking and listening in the primary school phase of the National Curriculum for England and Wales with learners of English as an additional language (EAL; Leung and Teasdale, 1997a; 1997b; Teasdale and Leung, 1997) in order to exemplify some of the issues raised and to illustrate the impact of assessment arrangements which has been inadequately conceptualized. The issues raised here are not necessarily age specific. II Alternative assessment and the psychometric paradigm A particular focus of interest in the literature has been the degree to which alternative assessment practices conform to the conceptualizations of validity which are current in more traditional psychometric approaches (see, amongst others, Gipps, 1992; Miller and Legg, 1993; Wiliam, 1993; Messick, 1995; Moss, 1995). However, a psychometric perspective is not the only reference point for alternative assessment. One claim is that ‘traditional’ validity frameworks operate from perspectives which are incompatible with the goals of alternative assessment. Additionally, alternative assessment is often associated with arguments for different conceptualizations of validity (TGAT, 1988; Nitko, 1989; Valdez Pierce and O’Malley, 1992; Gipps, 1994; Shepard et al., 1996). Huerta-Macı´as (1995: 9), writing in the US context, argues, in a way reminiscent of some of the early claims to validity of communicative language testing (e.g., Clark, 1978; Jones, 1985), that classroom-based teacher assessment of language has validity because ‘it looks at actual performance on real-life tasks, such as writing . . . participation in collaborative work . . . The procedures in and of themselves are, therefore, valid’. She further asserts that validity itself ensures reliability because it is very likely that a student engaged in a real learning task such as retelling a story will perform in similar ways from one week to the next. Shepard et al., (1996: 7) summarize some of the claims which have been made for classroom performance assessments: Performance assessments should enhance the validity of measurement by representing the full range of desired learning outcomes, by preserving the complexity of disciplinary knowledge domains and skills, by representing the contexts in which knowledge must ultimately be applied, and by adapting the modes of assessment to enable students to show what they know. The more assessments embody authentic criterion performances, the less we have to worry about drawing inferences from test results to remote constructs. Gipps (1994: 123) suggests that by assessing repeatedly over time, teachers can build up a ‘solid and broadly-based understanding of a pupil’s attainment’. Because of this ‘teacher assessment may be seen as having a high validity in relation to content and construct’ (p. 124). She also argues that if the information yielded by such assessment is to aid teaching and learning and that the outcome is improved learning, then it has consequential validity. Furthermore, if the sampling is of sufficient breadth and depth, then this kind of assessment is ‘generalizable’ within the particular domain in question. The kinds of claim Huerta-Macı´as makes are clearly not consistent with understandings of the nature of validity in psychometric approaches to measurement (e.g. Brown and Hudson, 1998). Validity appears to be narrowly conceived as a property of a procedure rather than of test scores (see Messick, 1989) and, what is more, a procedure within which close resemblance to real-life activity is taken as a sufficient condition to ensure validity (see Bachman, 1990). The claims of Gipps (1994), too, are difficult to reconcile with the kind of unitary approach to validity suggested in Messick (1989), since consequential validity is only one facet of ‘the unitary validity concept’ (p. 20); the interdependency of the concept – as proposed by Messick – precludes investigating single facets of the validity model without establishing the evidential bases of validity across the other relevant facets. Even if the central premise is accepted that ongoing sampling of classroom tasks of sufficient ‘breadth and depth’ allows for valid inferences to be made (an empirical question in itself), many questions remain. How many tasks? What type of tasks would fulfil the domain requirements? Are there tasks which would not? Is it assumed that the classroom and curriculum environment itself guarantees the domain relevance? How would we know whether it did or did not? However, it may be less important to ask these questions if the purpose of alternative assessment is to meet the needs of pedagogy. Arguably, where the stakes in assessment are lower (such as in ongoing schooling; however, see Rea-Dickins and Gardner, this issue) but where the impact on learning is an important consideration, then validity is liable to be reinterpreted. What is crucial in such situations is that the relationship (or lack of it) to psychometric notions of validity is made clear. All too often, aspects of psychometric theory are used to support positions which, in other crucial respects, are entirely untenable in psychometric terms. Downloaded from ltj.sagepub.com at TEXAS SOUTHERN UNIVERSITY on December 9, 2014 166 Teacher assessment and psychometric theory In the case of the Department for Education and Employment (DfEE), the body responsible for educational provision in England and Wales, there appears to be recognition that formal assessment and teacher assessment (i.e., two distinct approaches) provide different types of information. However, in making claims about the nature of information yielded, the validity requirements of the different approaches are ignored: Teacher assessment is an essential part of the National Curriculum assessment . . . Both [formal tests and teacher assessment] have equal status and provide complementary information about children’s attainment. The tests provide a standard ‘snapshot’ of attainment at the end of the key stage, while teacher assessment, carried out as part of teaching and learning in the classroom, covers the full range and scope of the programmes of study, and takes account of evidence of achievement in a range of contexts, including that gained through discussion and observation (DfEE, 1998: 9). In reality, the development and validation of the tests used seem to conform to standard psychometric practice; whereas the development and validation of teacher assessment have been neglected. For younger learners, particularly in educational systems which are committed to using information about pupil progress to inform pedagogy, teacher assessment is seen as an attractive option. However, implementing teacher assessment is not straightforward (as is shown by the examples presented in Rea-Dickins and Garner, this issue). The distinctions between testing (where psychometric and more traditional educational measurement principles guide practices) and teacher assessment (where both measurement and learning may be invoked) may be blurred. In the document cited above (DfEE, 1998), the threat to validity when using such different assessment approaches does not appear to have been addressed. Consequently, both what is measured and, therefore, the meanings which can be ascribed to scores are taken as unproblematic and somehow obvious. Another example can be found in a document published by TESOL (1998: 3) on assessment for the US context: Classroom assessments are those that are interwoven into instruction, often created and delivered by ESL/bilingual teachers. Large-scale assessments are those planned and conducted at the district, state, or national levels . . . The principles and discussions throughout this document refer to both large-scale and classroom assessment . . . The unproblematized grounding of both ‘classroom assessment’ and ‘large-scale assessment’ within a canonical educational measurement perspective is illustrated further in a discussion about reliability: Reliability is an assessment’s ability to produce consistent results. In other words, an assessment should yield the same results, or scores, from the same student. Many factors can jeopardize reliability, such as the instrument used Downloaded from ltj.sagepub.com at TEXAS SOUTHERN UNIVERSITY on December 9, 2014 Alex Teasdale and Constant Leung 167 to assess or the way the assessment is scored. . . If a student performs significantly differently on the same task within a short period of time, it is most likely a problem of the instrument and not the student . . . If one rater has been trained differently from another, or is using the criteria inconsistently, then a student may get different scores by different raters on the same task. 

Teacher assessment literacy: a review of international standards and measures Christopher DeLuca1 & Danielle LaPointe-McEwan1 & Ulemu Luhanga1 Received: 1 October 2014 /Accepted: 18 November 2015 # Springer Science+Business Media New York 2015 Abstract Assessment literacy is a core professional requirement across educational systems. Hence, measuring and supporting teachers’ assessment literacy have been a primary focus over the past two decades. At present, there are a multitude of assessment standards across the world and numerous assessment literacy measures that represent different conceptions of assessment literacy. The purpose of this research is to (a) analyze assessment literacy standards from five English-speaking countries (i.e., Australia, Canada, New Zealand, UK, and USA) plus mainland Europe to understand shifts in the assessment landscape over time and across regions and (b) analyze prominent assessment literacy measures developed after 1990. Through a thematic analysis of 15 assessment standards and an examination of eight assessment literacy measures, results indicate noticeable shifts in standards over time yet the majority of measures continue to be based on early conceptions of assessment literacy. Results also serve to define the multiple dimensions of assessment literacy and yield important recommendations for measuring teacher assessment literacy 2 Methods A two-phase research design was used to achieve the dual purposes of this study. The first phase involved collecting and analyzing documents describing teacher assessment literacy standards from various regions: Australia, Canada, New Zealand, UK, USA, and mainland Europe. To build on Gotch and French’s (2014) review, the second phase involved examining post-1990 assessment literacy measures to analyze the degree to which these measures align with contemporary assessment standards. 2.1 Phase 1: analysis of assessment literacy standards Assessment standards were selected from the six English-speaking regions (i.e., Australia, Canada, New Zealand, UK, USA, and mainland Europe). These regions have a demonstrated commitment to the advancement of classroom assessment research, policy, and practice as evident by their longstanding representation (since 2001) at the International Symposium for Classroom Assessment (ISCA n.d.) and with assessment leaders within the Consortium of International Researchers in Classroom Assessment. These countries have dedicated Bstandards^ documents that shape and guide teacher practice in the area of classroom assessment. That said, it is important to note that other countries and regions have strong traditions in classroom assessment with delineated policies for teacher practice (both English-speaking and not). Hence, the regional selection criteria for this study while justified do represent a generalizability limitation with this research. Therefore, we assert this study as a starting point for future research on assessment standards for teacher practice. Within the selected countries and regions, assessment standards were systematically identified by reviewing: (a) public websites for national or inter-state organizations and governmental ministries of education (e.g., Australian Department of Education, Department of Education in the United Kingdom, and US Department of Education); (b) national or inter-state assessment research consortia, associations, and joint advisory committees (e.g., Assessment and Certification Authorities, Assessment Reform Group, Association for Educational Assessment-Europe, Australian Curriculum, Joint Advisory Committee-Canada, National Council on Measurement in Education, and Joint Committee for Standards on Educational Evaluation); and (c) national and regional teacher education associations (e.g., Interstate Teacher Assessment and Support Consortium, National Board for Professional Teaching Standards, and National Council for the Accreditation of Teacher Education). Only documents that explicitly addressed Bstandards^ for teacher competency or literacy in assessment of student learning were selected for further analysis; in total, 15 standards documents were identified (see Table 1). Only national or inter-state level policies were used for this analysis. In countries with decentralized educational systems in which education falls within state or provincial jurisdiction (e.g., Canada and the USA), there may be additional policies that operate at state/provincial levels. All 15 documents were first coded by region and date of publication. Documents were then analyzed inductively using standard thematic coding procedures (Patton 2002) (see Table 2). The unit of analysis for thematic coding was each standard or, where applicable, its associated guidelines. For each document, frequencies were constructed to show the representation of each identified code. The total frequency of a code in relation to the total number of standards or guidelines within the document was calculated and expressed as a percentage. This proportion-based process reduced the inflation of frequency counts across documents with varying numbers of standards and/or guidelines (DeLuca and Bellara 2013). Codes were then collapsed into themes, and total percentages for each theme were reported (Tables 3 and 4). In total, we identified 35 codes that were collapsed into eight themes. These themes were (a) Assessment Purposes, (b) Assessment Processes, (c) Communication of Assessment Results, (d) Assessment Fairness, (e) Assessment Ethics, (f) Measurement Theory, (g) 3 Results 3.1 Assessment literacy: what is it? The results from phase 1 provide insight into standards that delineate teacher assessment literacy. Specifically, nine governmental and research-based assessment standards documents were included in our thematic analysis: five from the USA and one each from Canada, Australia, the UK, and mainland Europe. In addition, six standard documents from teacher accreditation and certification organizations were included; three from the USA and one each from New Zealand, Australia, and the UK. Prior to analyzing temporal and regional variations in these various documents, we briefly describe the number of standards and guidelines found within each document (see Table 1). 3.2 Governmental and research-based assessment standards In the USA, the Standards for Teacher Competence in Educational Assessment of Students (AFT et al. 1990) document was created to guide teacher educators and teachers in developing assessment competency. The document comprises seven standards that have been widely represented and reinforced in assessment textbooks for teachers, teacher education courses, policy documents, and educational research (Brookhart 2011) Three years later, the Principles for Fair Student Assessment Practices for Education in Canada (Joint Advisory Committee 1993) were published in Canada. This document consists of five standards and related guidelines intended to ensure fair assessment practices in Canadian educational contexts. The document is aimed at users and developers of classroom-based and standardized assessments. The document was generated from a cross-Canadian panel with two representatives appointed from nine Canadian educational organizations (i.e., Canadian Education Association, Canadian School Boards Association, Canadian Association for School Administrators, Canadian Teachers Federation, Canadian Guidance and Counselling Association, Canadian Association of School Psychologists, Canadian Council for Exceptional Children, Canadian Psychological Association, and Canadian Society for the Study of Education). Back in the USA, the National Council on Measurement in Education (NCME) produced the Code of Professional Responsibilities in Measurement in 1995. This extensive document was intended to guide all individuals involved in educational assessment activities, formal and informal, to Buphold the integrity of the manner in which assessment are developed, used, evaluated, and marketed^ (p. 1). The NCME document comprises eight standards with associated guidelines. In 1999, the America Educational Research Association, American Psychological Association, and National Council on Measurement in Education published the Standards for Educational and Psychological Testing. These sixteen standards serve as a reference for professional test developers, policy makers, and test users in the domains of education, psychology, and employment. A revised version is anticipated in 2014. Recognizing the limitations of previous assessment standards documents, Brookhart (2011) proposed a new set of educational assessment knowledge and skills for teachers. Specifically, Brookhart argued that the Standards for Teacher Competence in Educational Assessment of Students (AFT et al. 1990) failed to incorporate two significant developments in educational assessment: (a) formative assessment and (b) standards-based reform. Consequently, she proposed a set of 11 standards that reflect teachers’ current assessment competency needs. Most recently, the Joint Committee for Standards on Educational Evaluation (2015) released the Classroom Assessment Standards: Practices for PK-12 Teachers. This document includes 16 standards and related guidelines that illustrate essential considerations when Bexercising the professional judgment required for fair and equitable classroom formative, benchmark, and summative assessments for all students^ (p. 1). These standards can be used by teachers, students, and parents/guardians to support and enhance student learning. At the other ends of the globe, the Australian Curriculum, Assessment and Certification Authorities (ACACA 1995) produced the Guidelines for Assessment Quality and Equity. The primary focus of this document is to ensure quality, fair assessment in high stakes senior secondary assessment. This document includes 20 guidelines that address the quality of assessment methods, materials, and results. Over a decade later, in the UK, the Assessment Reform Group (2008) issued Changing Assessment Practices: Process, Principles and Standards. The purpose of this document is to guide and support change in assessment practice in educational contexts. Four broad standards and associated guidelines address: classroom teachers, school management teams, national/local governing bodies, and policy makers. Within each standard, assessment is discussed generally and in terms of formative and summative uses. In 2012, the Association for Educational Assessment-Europe (AEA-Europe) produced the European Framework of Standards for Educational Assessment 1.0. This framework is designated as a tool with seven core elements intended to support users of assessments as well as providers of assessment education and training. The framework incorporates both summative and formative uses of various types of assessments: standardized tests, classroom assessments, perfor

A CONCEPTUAL FRAMEWORK FOR INTEGRATING PEER ASSESSMENT IN TEACHER EDUCATION Dominique Sluijsmans and Frans Prins Open University of the Nether~ands, Heerlen, the Nether~ands Abstract Peer assessment can be a valuable learning tool in teacher education because it supports student teachers to acquire skills that are essential in their professional working life. This article presents a conceptual framework in which the training of peer assessment skills by means of peer assessment tasks is integrated in teacher education courses. Theories about constructive alignment, student involvement, instructional design, and performance assessment underlie the framework. Furthermore, two recently published empirical studies will be briefly described to provide empirical support for the value of the framework. Results of these studies show that the framework offers powerful guidelines for the design and integration of peer assessment activities in teacher training courses. In general, the peer assessment tasks that were embedded in the courses led to a general improvement in students' peer assessment skills as well as their task performance in the domain of the course. Implications for course and curriculum design are discussed. Designing Performance Assessments A common error in designing a course or unit of study is to leave the development of the performance assessment as a final activity (Airasian, 1991). The compatibility between learning, instruction and assessment is a basic assumption for our framework. Biggs' (1996, 1999, 2001) theory of constructive alignment and Stiggins' (1987) approach are useful to design courses and performance assessments. Four steps can be taken to design courses in which instruction and assessments are completely aligned. First, teachers must have a clearly defined purpose of a course. The concepts, skills, and knowledge to be assessed, as well as the level at which students should be performing, must be determined (Stiggins, D. Sluijsmans, E Prins /Studies' in Educational Evaluation 32 (2006) 6-22 1987). Second, it must be decided what type of activity best suits the assessment needs. This can result in a skill decomposition in which the relevant skills are hierarchically ordered, or in which they are organized in a concept map. Third, decisions should be made concerning the assessment task. Issues that must be taken into account are time constraints, availability of resources, and how many data are necessary in order to make an informed decision about the quality of a student's performance. Finally, after the assessment task is determined, the elements of the task that determine the measure of success of the student's performance need to be defined. Sometimes, these can be found in so-called job profiles. Most of the time, teachers have to analyse skills or products to identify performance criteria upon which to judge achievement, which is not an easy task. Criteria should be significant, specifying important performance components, represent standards that would apply naturally to determine the quality of performance when it typically occurs (Quellmalz, 1991). The criteria must be communicated clearly to, and be able to be understood by, all involved. Communicating information about performance criteria provides a basis for the improvement of that performance. When a teacher has passed through this procedure, study tasks can be designed in which students are prepared for the performance assessment. These study tasks are directly related to the performance assessment task at the end of the course. Designing Courses in Which Peer Assessment is Integrated According to Sluijsmans, Dochy, and Moerkerke (1999), teacher educators should be supported in the design of learning activities in which peer assessment is integrated. Stiggins's (1987) abovementioned design guidelines are helpful. Step 1 of the design process is to define the purpose of a course. It should be emphasized that a course that includes peer assessment tasks contains multiple learning goals. The performance of the student at the end of the course is content related and can be labelled as thefirst order goal of a course. Acquiring peer assessment skills is subsequently integrated as a higher order goal in a particular course. Students learn to evaluate the course content-related performances of peers at the end of a course. Peer assessment can thus be considered as a performance assessment that is superimposed on the content-related performance assessment. When the acquisition of peer assessment skills is one of the purposes of a course, students should be capable, at the end of the course, of making arrangements in which they negotiate with students of similar status about the design and appropriate criteria of specific study tasks and performances. Each student should also be able to take the responsibility to make critical judgements about the performances of a peer applying the appropriate criteria. It should be noted that peer assessment skills are not easily and automatically acquired. Peer assessment is considered a complex skill that needs to be developed (Birenbaum, 1996; Reilly Freese, 1999; Sluijsmans, Dochy, Moerkerke, & Van
